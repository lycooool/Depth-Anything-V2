{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "073f34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "# 讓 Python 能找到上層路徑的模組\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset.LayeredDepth_Syn import LayeredDepth_Syn\n",
    "from depth_anything_v2.dpt_finetune_1 import DepthAnythingV2\n",
    "from util.dist_helper import setup_distributed\n",
    "from util.loss import SiLogLoss\n",
    "from util.metric import eval_depth\n",
    "from util.utils import init_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19583554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model', 'optimizers', 'epoch', 'previous_best'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DepthAnythingV2(\n",
       "  (pretrained): DinoVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x NestedTensorBlock(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MemEffAttention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (depth_heads): ModuleList(\n",
       "    (0-3): 4 x DPTHead(\n",
       "      (projects): ModuleList(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2-3): 2 x Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (resize_layers): ModuleList(\n",
       "        (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): Identity()\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (refinenet1): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (output_conv2): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DepthAnythingV2model = DepthAnythingV2(encoder='vitl', features=256, out_channels=[256, 512, 1024, 1024])\n",
    "ckpt = torch.load(\"/home/lyc/research/Depth-Anything-V2/metric_depth/result_finetune_1/latest_epoch30.pth\", map_location=\"cuda\")\n",
    "print(type(ckpt))\n",
    "print(ckpt.keys())\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model = model.cuda()    # 或 model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fed7c8bac24f44ae10f407776a32fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5a9d0cb62c4672a7d66d49e5bde29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:57<00:00,  2.81it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "save_dir = \"val_vis\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "valset = LayeredDepth_Syn(mode = 'validation')\n",
    "valloader = DataLoader(valset, batch_size=1, pin_memory=True, num_workers=4, drop_last=True)\n",
    "progress_bar_val = tqdm(\n",
    "            enumerate(valloader),\n",
    "            total=len(valloader),\n",
    "            ncols=100,\n",
    "            dynamic_ncols=True\n",
    "        )\n",
    "\n",
    "for i, sample in progress_bar_val:\n",
    "    \n",
    "    img = sample['image'].cuda().float()\n",
    "    depth_l1, valid_mask_l1 = sample['d1'].cuda(), sample['d1_valid_mask'].cuda()\n",
    "    depth_l3, valid_mask_l3 = sample['d3'].cuda(), sample['d3_valid_mask'].cuda()\n",
    "    depth_l5, valid_mask_l5 = sample['d5'].cuda(), sample['d5_valid_mask'].cuda()\n",
    "    depth_l7, valid_mask_l7 = sample['d7'].cuda(), sample['d7_valid_mask'].cuda()\n",
    "    with torch.no_grad():\n",
    "        preds = model(img)\n",
    "\n",
    "     # ✅ 只顯示第一筆\n",
    "    # ✅ 只顯示第一筆樣本\n",
    "    # ---- 1️⃣ 反標準化影像 ----\n",
    "    img_vis = img[0].detach().cpu().permute(1, 2, 0).numpy()\n",
    "    img_vis = np.clip((img_vis * np.array([0.229, 0.224, 0.225]) +\n",
    "                    np.array([0.485, 0.456, 0.406])), 0, 1)\n",
    "    img_vis = (img_vis[:, :, ::-1] * 255).astype(np.uint8)  # RGB→BGR for cv2\n",
    "\n",
    "    # ---- 2️⃣ 預測與 GT 深度圖 ----\n",
    "    pred_vis = [p[0].detach().cpu().numpy() for p in preds]\n",
    "    gt_vis = [depth_l1[0].detach().cpu().numpy(),\n",
    "            depth_l3[0].detach().cpu().numpy(),\n",
    "            depth_l5[0].detach().cpu().numpy(),\n",
    "            depth_l7[0].detach().cpu().numpy()]\n",
    "    mask_vis = [valid_mask_l1[0].detach().cpu().numpy(),\n",
    "                valid_mask_l3[0].detach().cpu().numpy(),\n",
    "                valid_mask_l5[0].detach().cpu().numpy(),\n",
    "                valid_mask_l7[0].detach().cpu().numpy()]\n",
    "\n",
    "    # ---- 3️⃣ normalize depth & mask for visualization ----\n",
    "    def colorize_depth(depth):\n",
    "        d_norm = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        return cv2.applyColorMap(d_norm, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    def colorize_mask(mask):\n",
    "        m = (mask * 255).astype(np.uint8)\n",
    "        return cv2.cvtColor(m, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    pred_color = [colorize_depth(d) for d in pred_vis]\n",
    "    gt_color = [colorize_depth(d) for d in gt_vis]\n",
    "    mask_color = [colorize_mask(m) for m in mask_vis]\n",
    "\n",
    "    # ---- 4️⃣ 拼接圖像 ----\n",
    "    # ---- 4️⃣ 拼接圖像 ----\n",
    "    blank = np.zeros_like(pred_color[0])  # 建立空白灰圖，大小與 depth 相同\n",
    "\n",
    "    # 第一行：輸入影像 + 預測\n",
    "    row1 = np.concatenate([img_vis] + pred_color, axis=1)\n",
    "\n",
    "    # 第二行：空白 + GT 深度\n",
    "    row2 = np.concatenate([blank] + gt_color, axis=1)\n",
    "\n",
    "    # 第三行：空白 + Mask\n",
    "    row3 = np.concatenate([blank] + mask_color, axis=1)\n",
    "    vis_img = np.concatenate([row1, row2, row3], axis=0)\n",
    "\n",
    "    # ---- 5️⃣ 儲存 ----\n",
    "    save_path = os.path.join(save_dir, f\"sample_{i:04d}.png\")\n",
    "    cv2.imwrite(save_path, vis_img)\n",
    "    #print(f\"✅ Saved visualization: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Depth-Anything-V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
